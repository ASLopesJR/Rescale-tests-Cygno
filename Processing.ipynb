{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kzcLeyVQ2Ul7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amaro/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXspa8QEelWB"
   },
   "source": [
    "# Extract and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ES0vofeq13Ky",
    "outputId": "0f1edd48-4095-4d99-fad5-65f4511e57d3"
   },
   "outputs": [],
   "source": [
    "#!git clone -b v7 https://github.com/CYGNUS-RD/reconstruction.git  \n",
    "#!wget -P ./reconstruction/pedestals/ -N http://191.252.179.152/files/pedmap_run2155_rebin1.root\n",
    "#!wget -P ./reconstruction/ -N http://191.252.179.152/files/configFilef55.txt\n",
    "#!wget -P /mnt/ssdcache/amaro/ -N https://s3.cloud.infn.it/v1/AUTH_2ebf769785574195bde2ff418deac08a/cygnus/Data/LAB/histograms_Run02163.root\n",
    "#!mv /content/reconstruction/pedestals/pedmap_run02155_rebin1.root /content/reconstruction/pedestals/pedmap_run2155_rebin1.root\n",
    "#!mkdir -p ./plots\n",
    "#!sed -i 's/expand_noncore, debug=True/expand_noncore, debug=False/g' ./reconstruction/cluster/ddbscan_inner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mufo6LwJ4Y2w"
   },
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-jOjOrF50QAt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "tries = 1\n",
    "ini = 0\n",
    "fin = 0\n",
    "sizes = [2, 4, 8, 16, 32]\n",
    "#sizes = [4]\n",
    "# sizes = [4, 2]\n",
    "# sizes = [1, 2, 3, 4, 5, \\\n",
    "#         6, 7, 8, 9, 10,\\\n",
    "#         11, 12, 13, 14,\\\n",
    "#         15, 16, 17, 18,\\\n",
    "#         19, 20, 21, 22,\\\n",
    "#         23, 24, 25, 26,\\\n",
    "#         27, 28, 29, 30,\\\n",
    "#         31, 32]\n",
    "\n",
    "t_cython = np.zeros([tries,(fin-ini+1)]) \n",
    "t_nocyth = np.zeros([tries,(fin-ini+1)]) \n",
    "numberofevents = [1000]#[10, 25, 50, 100, 150, 200]\n",
    "\n",
    "path = Path(r'/home/amaro/notebooks/simulations')\n",
    "#path = Path(r'/home/amaro/notebooks/aquisitions') #done\n",
    "#path = Path(r'/home/amaro/notebooks/pedestals') #done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTPpddna17bd"
   },
   "source": [
    "# Cython module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amaro/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi5VQgg3BwXA",
    "outputId": "887e0a88-14f2-428f-c074-18ed4e14f48b"
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tikCtsTKAt6o"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "DTYPE = np.float\n",
    "\n",
    "ctypedef np.float_t DTYPE_t\n",
    "\n",
    "\n",
    "def nred_cython(np.ndarray[DTYPE_t, ndim=2] edges, int escala, float meancut=0.35):\n",
    "    cdef int rescale = escala \n",
    "    cdef int tpx = 10\n",
    "    cdef float mpx\n",
    "    cdef float a,b,c,d,spx,f,g,h,i\n",
    "    cdef int neighbors\n",
    "    \n",
    "    cdef int k, j\n",
    "\n",
    "    for k in range(rescale):\n",
    "        for j in range(2):\n",
    "            edges[j,k]=0\n",
    "            edges[k,j]=0\n",
    "            edges[rescale-1-j,k]=0\n",
    "            edges[k,rescale-1-j]=0\n",
    "\n",
    "    for k in range(1,rescale-2):\n",
    "        for j in range(1,rescale-2):\n",
    "            a = edges[k-1,j-1]\n",
    "            b = edges[k,j-1]\n",
    "            c = edges[k+1,j-1]\n",
    "            d = edges[k-1,j]\n",
    "            spx = edges[k,j]\n",
    "            f = edges[k+1,j]\n",
    "            g = edges[k-1,j+1]\n",
    "            h = edges[k,j+1]\n",
    "            i = edges[k+1,j+1]\n",
    "            mpx = (a+b+c+d+f+g+h+i)/8.\n",
    "            # put very noisy pixels at the average value of the frame around\n",
    "            if abs(spx - mpx) > tpx :\n",
    "                edges[k,j] = mpx\n",
    "            # filter the pixels with no sufficient energy around\n",
    "            if (mpx < 0.35):\n",
    "                edges[k,j] = 0\n",
    "            # require at least two neighbors above threshold\n",
    "            #frame = edges[k-1:k+2,j-1:j+2]\n",
    "            neighbors = 9-(not a)-(not b)-(not c)-(not d)-(not spx)-(not f)-(not g)-(not h)-(not i)\n",
    "            if neighbors<3:\n",
    "                edges[k,j] = 0\n",
    "    return edges\n",
    "\n",
    "\n",
    "def sim3d_cython(np.ndarray[np.int_t, ndim=2] img_rb_zs, np.ndarray[np.int_t, ndim=2] points):\n",
    "    cdef int size = points.shape[0]\n",
    "    cdef int k, nreplicas=0\n",
    "    cdef np.int_t j,l,idx1=0,idx2=0\n",
    "    for k in range(size):\n",
    "        j = points[k,0]\n",
    "        l = points[k,1]\n",
    "        if (img_rb_zs[j,l] == 0):\n",
    "            nreplicas += 1\n",
    "        else:\n",
    "            nreplicas += img_rb_zs[j,l] \n",
    "    cdef np.ndarray[np.int64_t, ndim=2] newpoints = np.zeros((nreplicas,2), dtype=np.int64)\n",
    "    cdef int count=0\n",
    "    for k in range(size):\n",
    "        j = points[k,0]\n",
    "        l = points[k,1]\n",
    "        nreplicas = img_rb_zs[j,l]\n",
    "        if (nreplicas < 1):\n",
    "            newpoints[idx1,0] = j\n",
    "            newpoints[idx1,1] = l\n",
    "            idx1 += 1\n",
    "        else:\n",
    "            newpoints[(idx1),0] = j\n",
    "            newpoints[(idx1),1] = l\n",
    "            idx1 += 1\n",
    "            for count in range(nreplicas-1):\n",
    "                newpoints[(idx2+size),0] = j\n",
    "                newpoints[(idx2+size),1] = l\n",
    "                idx2 += 1\n",
    "    return newpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHbAaXce43SH"
   },
   "source": [
    "# With Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNnAK4Ie1Xq_"
   },
   "source": [
    "## Snakes module with cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBwQl5KLKCP4",
    "outputId": "beaf661d-f42f-49fb-afd4-91757a1b960c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amaro/notebooks/reconstruction\n",
      "Welcome to JupyROOT 6.22/09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaro/.local/lib/python3.10/site-packages/root_numpy/__init__.py:40: RuntimeWarning: numpy 1.22.2 is currently installed but you installed root_numpy against numpy 1.21.4. Please consider reinstalling root_numpy for this numpy version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%cd reconstruction/\n",
    "\n",
    "import numpy as np\n",
    "import ROOT,math,os,sys,time\n",
    "import pickle\n",
    "\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "from skimage import measure\n",
    "\n",
    "from morphsnakes import(morphological_chan_vese,\n",
    "                        morphological_geodesic_active_contour,\n",
    "                        inverse_gaussian_gradient,\n",
    "                        checkerboard_level_set)\n",
    "\n",
    "from clusterTools import Cluster\n",
    "from cameraChannel import cameraTools\n",
    "from cluster.ddbscan_ import DDBSCAN\n",
    "from energyCalibrator import EnergyCalibrator\n",
    "\n",
    "import debug_code.tools_lib as tl\n",
    "\n",
    "class SnakesFactory:\n",
    "    def __init__(self,img,img_fr,img_fr_zs,img_ori,vignette,name,options,geometry):\n",
    "        self.name = name\n",
    "        self.options = options\n",
    "        self.rebin = options.rebin\n",
    "        self.geometry = geometry\n",
    "        self.ct = cameraTools(geometry)\n",
    "        self.image = img\n",
    "        self.img_ori = img_ori\n",
    "        self.imagelog = np.zeros((self.image.shape[0],self.image.shape[1]))\n",
    "        for (x,y),value in np.ndenumerate(self.image):\n",
    "            if value > 3.0/math.sqrt(self.rebin): # tresholding needed for tracking\n",
    "                self.imagelog[x,y] = math.log(value)\n",
    "        self.image_fr    = img_fr\n",
    "        self.image_fr_zs = img_fr_zs\n",
    "        self.vignette = vignette\n",
    "        self.contours = []\n",
    "        \n",
    "    def getClusters(self,plot=False):\n",
    "\n",
    "        from sklearn.cluster import DBSCAN\n",
    "        from sklearn import metrics\n",
    "        from scipy.spatial import distance\n",
    "        from scipy.stats import pearsonr\n",
    "        from random import random\n",
    "\n",
    "        outname = self.options.plotDir\n",
    "        if outname and not os.path.exists(outname):\n",
    "            os.system(\"mkdir -p \"+outname)\n",
    "            os.system(\"cp utils/index.php \"+outname)\n",
    "        \n",
    "        #   Plot parameters  #\n",
    "        \n",
    "        vmin=1\n",
    "        vmax=5\n",
    "        \n",
    "        tip = self.options.tip\n",
    "        \n",
    "        #-----Pre-Processing----------------#\n",
    "        rescale=int(self.geometry.npixx/self.rebin)\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        filtimage = median_filter(self.image_fr_zs, size=2)\n",
    "        edges = self.ct.arrrebin(filtimage,self.rebin)\n",
    "        edcopy = edges.copy()\n",
    "        #edcopyTight = tl.noisereductor(edcopy,rescale,self.options.min_neighbors_average)\n",
    "        edcopyTight = nred_cython(edcopy,rescale,self.options.min_neighbors_average)\n",
    "\n",
    "\n",
    "        # make the clustering with DBSCAN algo\n",
    "        # this kills all macrobins with N photons < 1\n",
    "        points = np.array(np.nonzero(np.round(edcopyTight))).astype(int).T\n",
    "        lp = points.shape[0]\n",
    "\n",
    "        ## apply vignetting (if not applied, vignette map is all ones)\n",
    "        ## this is done only for energy calculation, not for clustering (would make it crazy)\n",
    "        image_fr_vignetted = self.ct.vignette_corr(self.image_fr,self.vignette)\n",
    "        image_fr_zs_vignetted = self.ct.vignette_corr(self.image_fr_zs,self.vignette)\n",
    "                \n",
    "        if tip=='3D':\n",
    "            sample_weight = np.take(self.image, self.image.shape[0]*points[:,0]+points[:,1]).astype(int)\n",
    "            sample_weight[sample_weight==0] = 1\n",
    "            X = points.copy()\n",
    "            \n",
    "        else:\n",
    "            X = points.copy()\n",
    "            sample_weight = np.full(X.shape[0], 1, dtype=np.int)\n",
    "\n",
    "        # returned collections\n",
    "        superclusters = []\n",
    "\n",
    "        # clustering will crash if the vector of pixels is empty (it may happen after the zero-suppression + noise filtering)\n",
    "        if len(X)==0:\n",
    "            return superclusters\n",
    "\n",
    "        # - - - - - - - - - - - - - -\n",
    "        t1 = time.perf_counter()\n",
    "        ddb = DDBSCAN('modules_config/clustering.txt').fit(X, sample_weight = sample_weight)\n",
    "        t2 = time.perf_counter()\n",
    "        \n",
    "        # Black removed and is used for noise instead.\n",
    "        unique_labels = set(ddb.labels_[:,0])\n",
    "\n",
    "        # Number of polynomial clusters in labels, ignoring noise if present.\n",
    "        n_superclusters = len(unique_labels) - (1 if -1 in ddb.labels_[:,0] else 0)\n",
    "\n",
    "        for k in unique_labels:\n",
    "            if k == -1:\n",
    "                break # noise: the unclustered\n",
    "\n",
    "            class_member_mask = (ddb.labels_[:,0] == k)\n",
    "            xy = np.unique(X[class_member_mask],axis=0)\n",
    "            x = xy[:, 0]; y = xy[:, 1]\n",
    "            \n",
    "            # both core and neighbor samples are saved in the cluster in the event\n",
    "            if k>-1 and len(x)>1:\n",
    "                cl = Cluster(xy,self.rebin,image_fr_vignetted,image_fr_zs_vignetted,self.options.geometry,debug=False)\n",
    "                cl.iteration = 0\n",
    "                cl.nclu = k\n",
    "                cl.pearson = 999#p_value\n",
    "                superclusters.append(cl)\n",
    "                \n",
    "        t2 = time.perf_counter()\n",
    "\n",
    "        ## DEBUG MODE\n",
    "\n",
    "        return superclusters\n",
    "        \n",
    "    def getTracks(self,plot=True):\n",
    "        from skimage.transform import (hough_line, hough_line_peaks)\n",
    "        # Classic straight-line Hough transform\n",
    "        image = self.imagelog\n",
    "        h, theta, d = hough_line(image)\n",
    "        print(\"tracks found\")\n",
    "        \n",
    "        tracks = []\n",
    "        thr = 0.8 * np.amax(h)\n",
    "        #######################   IMPLEMENT HERE THE SAVING OF THE TRACKS ############\n",
    "        # loop over prominent tracks\n",
    "        itrk = 0\n",
    "        for _, angle, dist in zip(*hough_line_peaks(h, theta, d,threshold=thr)):\n",
    "            print(\"Track # \",itrk)\n",
    "            #points_along_trk = np.zeros((self.image.shape[1],self.image.shape[0]))\n",
    "            points_along_trk = []\n",
    "            for x in range(self.image.shape[1]):\n",
    "                y = min(self.image.shape[0],max(0,int((dist - x * np.cos(angle)) / np.sin(angle))))\n",
    "                #points_along_trk[x,y] = self.image[y,x]\n",
    "                #print \"adding point: %d,%d,%f\" % (x,y,self.image[y,x])\n",
    "                # add a halo fo +/- 20 pixels to calculate the lateral profile\n",
    "                for iy in range(int(y)-5,int(y)+5):\n",
    "                    if iy<0 or iy>=self.image.shape[0]: continue\n",
    "                    points_along_trk.append((x,iy,self.image[iy,x]))\n",
    "            xy = np.array(points_along_trk)\n",
    "            trk = Cluster(xy,self.rebin)\n",
    "            tracks.append(trk)\n",
    "            itrk += 1\n",
    "        ###################################\n",
    "            \n",
    "        if plot:\n",
    "            # Generating figure\n",
    "            from matplotlib import cm\n",
    "            fig, ax = plt.subplots(2, 1, figsize=(18, 6))\n",
    "            #ax = axes.ravel()\n",
    "\n",
    "            ax[0].imshow(image, cmap=cm.gray)\n",
    "            ax[0].set_title('Camera image')\n",
    "            #ax[0].set_axis_off()            \n",
    "\n",
    "            ax[1].imshow(image, cmap=cm.gray)\n",
    "            for _, angle, dist in zip(*hough_line_peaks(h, theta, d,threshold=thr)):\n",
    "                y0 = (dist - 0 * np.cos(angle)) / np.sin(angle)\n",
    "                y1 = (dist - image.shape[1] * np.cos(angle)) / np.sin(angle)\n",
    "                ax[1].plot((0, image.shape[1]), (y0, y1), '-r')\n",
    "            ax[1].set_xlim((0, image.shape[1]))\n",
    "            ax[1].set_ylim((image.shape[0], 0))\n",
    "            #ax[1].set_axis_off()\n",
    "            ax[1].set_title('Fitted tracks')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            #plt.show()\n",
    "            outname = self.options.plotDir\n",
    "            if outname and not os.path.exists(outname):\n",
    "                os.system(\"mkdir -p \"+outname)\n",
    "                os.system(\"cp ~/cernbox/www/Cygnus/index.php \"+outname)\n",
    "            for ext in ['pdf']:\n",
    "                plt.savefig('{pdir}/{name}.{ext}'.format(pdir=outname,name=self.name,ext=ext))\n",
    "            plt.gcf().clear()\n",
    "\n",
    "        return tracks\n",
    "        \n",
    "    def plotClusterFullResolution(self,clusters):\n",
    "        outname = self.options.plotDir\n",
    "        for k,cl in enumerate(clusters):\n",
    "            cl.plotFullResolution('{pdir}/{name}_cluster{iclu}'.format(pdir=outname,name=self.name,iclu=k))\n",
    "\n",
    "    def calcProfiles(self,clusters,plot=False):\n",
    "        for k,cl in enumerate(clusters):\n",
    "            profName = '{name}_cluster{iclu}'.format(name=self.name,iclu=k)\n",
    "            cl.calcProfiles(name=profName,plot=plot)\n",
    "                             \n",
    "    def plotProfiles(self,clusters):\n",
    "        print (\"plot profiles...\")\n",
    "        outname = self.options.plotDir\n",
    "        canv = ROOT.TCanvas('c1','',1200,600)\n",
    "        for k,cl in enumerate(clusters):\n",
    "            for dir in ['long','lat']:\n",
    "                profName = '{name}_cluster{iclu}_{dir}'.format(name=self.name,iclu=k,dir=dir)\n",
    "                prof = cl.getProfile(dir)\n",
    "                if prof and cl.widths[dir]>0.2: # plot the profiles only of sufficiently long snakes (>200 um)\n",
    "                    prof.Draw(\"pe1\")\n",
    "                    for ext in ['pdf']:\n",
    "                        canv.SaveAs('{pdir}/{name}profile.{ext}'.format(pdir=outname,name=profName,ext=ext))\n",
    "\n",
    "class SnakesProducer:\n",
    "    def __init__(self,sources,params,options,geometry):\n",
    "        self.picture     = sources['picture']     if 'picture' in sources else None\n",
    "        self.pictureHD   = sources['pictureHD']   if 'pictureHD' in sources else None\n",
    "        self.picturezsHD = sources['picturezsHD'] if 'picturezsHD' in sources else None\n",
    "        self.pictureOri  = sources['pictureOri']  if 'pictureOri' in sources else None\n",
    "        self.vignette    = sources['vignette']    if 'vignette' in sources else None\n",
    "        self.name        = sources['name']        if 'name' in sources else None\n",
    "        self.algo        = sources['algo']        if 'algo' in sources else 'DBSCAN'\n",
    "        \n",
    "        self.snakeQualityLevel = params['snake_qual']   if 'snake_qual' in params else 3\n",
    "        self.plot2D            = params['plot2D']       if 'plot2D' in params else False\n",
    "        self.plotpy            = params['plotpy']       if 'plotpy' in params else False\n",
    "        self.plotprofiles      = params['plotprofiles'] if 'plotprofiles' in params else False\n",
    "\n",
    "        self.options = options\n",
    "        self.geometry = geometry\n",
    "        geometryPSet   = open('modules_config/geometry_{det}.txt'.format(det=options.geometry),'r')\n",
    "        geometryParams = eval(geometryPSet.read())\n",
    "\n",
    "        self.run_cosmic_killer = self.options.cosmic_killer\n",
    "        if self.run_cosmic_killer:\n",
    "            from clusterMatcher import ClusterMatcher\n",
    "            # cosmic killer parameters\n",
    "            cosmicKillerPars = open('modules_config/clusterMatcher.txt','r')\n",
    "            killer_params = eval(cosmicKillerPars.read())\n",
    "            killer_params.update(geometryParams)\n",
    "            self.cosmic_killer = ClusterMatcher(killer_params)\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        ret = []\n",
    "        if any([x==None for x in (self.picture.any(),self.pictureHD.any(),self.picturezsHD.any(),self.name)]):\n",
    "            return ret\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        \n",
    "        # Cluster reconstruction on 2D picture\n",
    "        snfac = SnakesFactory(self.picture,self.pictureHD,self.picturezsHD,self.pictureOri,self.vignette,self.name,self.options,self.geometry)\n",
    "\n",
    "        # this plotting is only the pyplot representation.\n",
    "        # Doesn't work on MacOS with multithreading for some reason... \n",
    "        if self.algo=='DBSCAN':\n",
    "            snakes = snfac.getClusters(plot=self.plotpy)\n",
    "\n",
    "            # supercluster energy calibration for the saturation effect\n",
    "            fileCalPar = open('modules_config/energyCalibrator.txt','r')\n",
    "            params = eval(fileCalPar.read())\n",
    "            calibrator = EnergyCalibrator(params,self.options.debug_mode)\n",
    "            \n",
    "            for sclu in snakes:\n",
    "                if self.options.calibrate_clusters:\n",
    "                    calEnergy,slicesCalEnergy,centers = calibrator.calibratedEnergy(sclu.hits_fr)\n",
    "                else:\n",
    "                    calEnergy,slicesCalEnergy,centers = -1,[],[]\n",
    "                if self.options.debug_mode:\n",
    "                    print ( \"SUPERCLUSTER BARE INTEGRAL = {integral:.1f}\".format(integral=sclu.integral()) )\n",
    "                sclu.calibratedEnergy = calEnergy\n",
    "                sclu.nslices = len(slicesCalEnergy)\n",
    "                sclu.energyprofile = slicesCalEnergy\n",
    "                sclu.centers = centers\n",
    "                sclu.pathlength = -1 if self.options.calibrate_clusters==False else calibrator.clusterLength()    \n",
    "            \n",
    "        elif self.algo=='HOUGH':\n",
    "            clusters = []\n",
    "            snakes = snfac.getTracks(plot=self.plotpy)            \n",
    "        t1 = time.perf_counter()\n",
    "        if self.options.debug_mode: print(f\"FULL RECO in {t1 - t0:0.4f} seconds\")\n",
    "            \n",
    "        # print \"Get light profiles...\"\n",
    "        snfac.calcProfiles(snakes,plot=self.plotpy)\n",
    "        t2 = time.perf_counter()\n",
    "        if self.options.debug_mode: print(f\"cluster shapes in {t2 - t1:0.4f} seconds\")\n",
    "\n",
    "        # run the cosmic killer: it makes sense only on superclusters\n",
    "        if self.run_cosmic_killer:\n",
    "            for ik,killerCand in enumerate(snakes):\n",
    "                targets = [snakes[it] for it in range(len(snakes)) if it!=ik]\n",
    "                self.cosmic_killer.matchClusters(killerCand,targets)\n",
    "            t3 = time.perf_counter()\n",
    "            if self.options.debug_mode: print(f\"cosmic killer in {t3 - t2:0.4f} seconds\")\n",
    "\n",
    "        # snfac.calcProfiles(snakes) # this is for BTF\n",
    "        \n",
    "        # sort snakes by light integral\n",
    "        snakes = sorted(snakes, key = lambda x: x.integral(), reverse=True)\n",
    "        # and reject discharges (round)\n",
    "        #snakes = [x for x in snakes if x.qualityLevel()>=self.snakeQualityLevel]\n",
    "        \n",
    "        # plotting\n",
    "        if self.plot2D:       snfac.plotClusterFullResolution(snakes)\n",
    "        if self.plotprofiles: snfac.plotProfiles(snakes)\n",
    "\n",
    "        return snakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IE3j7Ld1ekC"
   },
   "source": [
    "## Main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8GGyLy13dR9Q",
    "outputId": "6ce9f16e-0bc2-4925-f702-2c8027aa1428",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histograms_Run08007.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=2 Correct=93\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08009.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=5 Correct=90\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08005.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=93 Correct=0\n",
      "Total Incorrect=93 Correct=0\n",
      "Total Incorrect=4 Correct=89\n",
      "Total Incorrect=0 Correct=93\n",
      "Total Incorrect=0 Correct=93\n",
      "histograms_Run02163-005.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=411 Correct=86\n",
      "Total Incorrect=190 Correct=307\n",
      "Total Incorrect=10 Correct=487\n",
      "Total Incorrect=0 Correct=497\n",
      "Total Incorrect=0 Correct=497\n",
      "histograms_Run08011.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08000.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08010.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=4 Correct=91\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08001.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08002.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=2 Correct=93\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08008.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=3 Correct=92\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08012.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08006.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08004.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "histograms_Run08003.root\n",
      "This run has  1000  events.\n",
      "Total Incorrect=95 Correct=0\n",
      "Total Incorrect=11 Correct=84\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n",
      "Total Incorrect=0 Correct=95\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "\n",
    "from multiprocessing import Pool,set_start_method,TimeoutError\n",
    "from subprocess import Popen, PIPE\n",
    "import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "\n",
    "import os,math,sys,random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import ROOT\n",
    "ROOT.gROOT.SetBatch(True)\n",
    "from root_numpy import hist2array\n",
    "from cameraChannel import cameraTools, cameraGeometry\n",
    "\n",
    "from snakes import SnakesProducer\n",
    "from output import OutputTree\n",
    "from treeVars import AutoFillTreeProducer\n",
    "import swiftlib as sw\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# this kills also the still running subprocesses.\n",
    "# use with a safe MAX TIMEOUT duration, since it will kill everything\n",
    "def terminate_pool_2(pool):\n",
    "    print (\"Some subprocess timed out. Killing it brutally.\")\n",
    "    os.system('killall -9 python3.8')\n",
    "\n",
    "# this still stucks\n",
    "def terminate_pool(pool):\n",
    "    print (\"Some subprocess timed out. Killing it brutally.\")\n",
    "    for p in pool._pool:\n",
    "        print (\"KILLING PID \",p.pid)\n",
    "        os.kill(p.pid, 9)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "\n",
    "def split(array, nrows, ncols):\n",
    "    r, h = array.shape\n",
    "    return (array.reshape(h//nrows, nrows, -1, ncols)\n",
    "                 .swapaxes(1, 2)\n",
    "                 .reshape(-1, nrows, ncols))\n",
    "    \n",
    "import utilities\n",
    "utilities = utilities.utils()\n",
    "\n",
    "class analysis:\n",
    "\n",
    "    def __init__(self,options):\n",
    "        self.rebin = options.rebin        \n",
    "        self.options = options\n",
    "        self.pedfile_fullres_name = options.pedfile_fullres_name\n",
    "        self.tmpname = options.tmpname\n",
    "        geometryPSet   = open('modules_config/geometry_{det}.txt'.format(det=options.geometry),'r')\n",
    "        geometryParams = eval(geometryPSet.read())\n",
    "        self.cg = cameraGeometry(geometryParams)\n",
    "        self.xmax = self.cg.npixx\n",
    "\n",
    "        if not os.path.exists(self.pedfile_fullres_name):\n",
    "            print(\"WARNING: pedestal file with full resolution \",self.pedfile_fullres_name, \" not existing. First calculate them...\")\n",
    "            self.calcPedestal(options,1)\n",
    "        if not options.justPedestal:\n",
    "           #print(\"Pulling pedestals...\")\n",
    "           # first the one for clustering with rebin\n",
    "            ctools = cameraTools(self.cg)\n",
    "           # then the full resolution one\n",
    "            pedrf_fr = ROOT.TFile.Open(self.pedfile_fullres_name)\n",
    "            self.pedmap_fr = pedrf_fr.Get('pedmap').Clone()\n",
    "            self.pedmap_fr.SetDirectory(0)\n",
    "            self.pedarr_fr = hist2array(self.pedmap_fr).T\n",
    "            self.noisearr_fr = ctools.noisearray(self.pedmap_fr).T\n",
    "            pedrf_fr.Close()\n",
    "            if options.vignetteCorr:\n",
    "                self.vignmap = ctools.loadVignettingMap()\n",
    "            else:\n",
    "                self.vignmap = np.ones((self.xmax, self.xmax))\n",
    "             \n",
    "\n",
    "    # the following is needed for multithreading\n",
    "    def __call__(self,evrange=(-1,-1,-1)):\n",
    "        if evrange[0]==-1:\n",
    "            outfname = self.options.outFile\n",
    "        else:\n",
    "            outfname = '{base}_chunk{ij}.root'.format(base=self.options.outFile.split('.')[0],ij=evrange[0])\n",
    "        self.beginJob(outfname)\n",
    "        self.reconstruct(evrange)\n",
    "        self.endJob()\n",
    "        \n",
    "    def beginJob(self,outfname):\n",
    "        # prepare output file\n",
    "        self.outputFile = ROOT.TFile.Open(outfname, \"RECREATE\")\n",
    "        # prepare output tree\n",
    "        self.outputTree = ROOT.TTree(\"Events\",\"Tree containing reconstructed quantities\")\n",
    "        self.outTree = OutputTree(self.outputFile,self.outputTree)\n",
    "        self.autotree = AutoFillTreeProducer(self.outTree)\n",
    "\n",
    "        self.outTree.branch(\"run\", \"I\")\n",
    "        self.outTree.branch(\"event\", \"I\")\n",
    "        self.outTree.branch(\"pedestal_run\", \"I\")\n",
    "        if self.options.camera_mode:\n",
    "            self.autotree.createCameraVariables()\n",
    "            self.autotree.createClusterVariables('cl')\n",
    "            self.autotree.createClusterVariables('sc')\n",
    "        if self.options.pmt_mode:\n",
    "            self.autotree.createPMTVariables()\n",
    "\n",
    "    def endJob(self):\n",
    "        self.outTree.write()\n",
    "        self.outputFile.Close()\n",
    "        \n",
    "    def getNEvents(self):\n",
    "        tf = sw.swift_read_root_file(self.tmpname) #tf = ROOT.TFile.Open(self.rfile)\n",
    "        ret = int(len(tf.GetListOfKeys())/2) if (self.options.daq=='midas' and self.options.pmt_mode) else len(tf.GetListOfKeys())\n",
    "        tf.Close()\n",
    "        return ret\n",
    "\n",
    "    def calcPedestal(self,options,alternativeRebin=-1):\n",
    "        maxImages=options.maxEntries\n",
    "        nx=ny=self.xmax\n",
    "        rebin = self.rebin if alternativeRebin<0 else alternativeRebin\n",
    "        nx=int(nx/rebin); ny=int(ny/rebin); \n",
    "        #pedfilename = 'pedestals/pedmap_ex%d_rebin%d.root' % (options.pedexposure,rebin)\n",
    "        pedfilename = 'pedestals/pedmap_run%s_rebin%d.root' % (options.run,rebin)\n",
    "        \n",
    "        pedfile = ROOT.TFile.Open(pedfilename,'recreate')\n",
    "        pedmap = ROOT.TH2D('pedmap','pedmap',nx,0,self.xmax,ny,0,self.xmax)\n",
    "        pedmapS = ROOT.TH2D('pedmapsigma','pedmapsigma',nx,0,self.xmax,ny,0,self.xmax)\n",
    "\n",
    "        pedsum = np.zeros((nx,ny))\n",
    "        \n",
    "        tf = sw.swift_read_root_file(self.tmpname)\n",
    "        #tf = ROOT.TFile.Open(self.rfile)\n",
    "\n",
    "        # first calculate the mean \n",
    "        numev = 0\n",
    "        for i,e in enumerate(tf.GetListOfKeys()):\n",
    "            iev = i if self.options.daq != 'midas' and self.options.pmt_mode else i/2 # when PMT is present\n",
    "            if iev in self.options.excImages: continue\n",
    "            if maxImages>-1 and i>min(len(tf.GetListOfKeys()),maxImages): break\n",
    "            \n",
    "            name=e.GetName()\n",
    "            obj=e.ReadObj()\n",
    "\n",
    "            if not obj.InheritsFrom('TH2'): continue\n",
    "            print(\"Calc pedestal mean with event: \",name)\n",
    "            if rebin>1:\n",
    "                obj.RebinX(rebin);\n",
    "                obj.RebinY(rebin); \n",
    "            arr = hist2array(obj)\n",
    "            pedsum = np.add(pedsum,arr)\n",
    "            numev += 1\n",
    "        pedmean = pedsum / float(numev)\n",
    "\n",
    "        # now compute the rms (two separate loops is faster than one, yes)\n",
    "        numev=0\n",
    "        pedsqdiff = np.zeros((nx,ny))\n",
    "        for i,e in enumerate(tf.GetListOfKeys()):\n",
    "            iev = i if self.options.daq != 'midas' and self.options.pmt_mode else i/2 # when PMT is present\n",
    "            if iev in self.options.excImages: continue\n",
    "            if maxImages>-1 and i>min(len(tf.GetListOfKeys()),maxImages): break\n",
    "            \n",
    "            name=e.GetName()\n",
    "            obj=e.ReadObj()\n",
    "            if not obj.InheritsFrom('TH2'): continue\n",
    "            print(\"Calc pedestal rms with event: \",name)\n",
    "            if rebin>1:\n",
    "                obj.RebinX(rebin);\n",
    "                obj.RebinY(rebin); \n",
    "            arr = hist2array(obj)\n",
    "            pedsqdiff = np.add(pedsqdiff, np.square(np.add(arr,-1*pedmean)))\n",
    "            numev += 1\n",
    "        pedrms = np.sqrt(pedsqdiff/float(numev-1))\n",
    "\n",
    "        # now save in a persistent ROOT object\n",
    "        for ix in range(nx):\n",
    "            for iy in range(ny):\n",
    "                pedmap.SetBinContent(ix+1,iy+1,pedmean[ix,iy]);\n",
    "                pedmap.SetBinError(ix+1,iy+1,pedrms[ix,iy]);\n",
    "                pedmapS.SetBinContent(ix+1,iy+1,pedrms[ix,iy]);\n",
    "        tf.Close()\n",
    "\n",
    "        pedfile.cd()\n",
    "        pedmap.Write()\n",
    "        pedmapS.Write()\n",
    "        pedmean1D = ROOT.TH1D('pedmean','pedestal mean',500,97,103)\n",
    "        pedrms1D = ROOT.TH1D('pedrms','pedestal RMS',500,0,5)\n",
    "        for ix in range(nx):\n",
    "            for iy in range(ny):\n",
    "               pedmean1D.Fill(pedmap.GetBinContent(ix,iy)) \n",
    "               pedrms1D.Fill(pedmap.GetBinError(ix,iy)) \n",
    "        pedmean1D.Write()\n",
    "        pedrms1D.Write()\n",
    "        pedfile.Close()\n",
    "        print(\"Pedestal calculated and saved into \",pedfilename)\n",
    "\n",
    "\n",
    "    def reconstruct(self,n=4,evrange=(-1,-1,-1)):\n",
    "\n",
    "        ROOT.gROOT.Macro('rootlogon.C')\n",
    "        ROOT.gStyle.SetOptStat(0)\n",
    "        ROOT.gStyle.SetPalette(ROOT.kRainBow)\n",
    "        savErrorLevel = ROOT.gErrorIgnoreLevel; ROOT.gErrorIgnoreLevel = ROOT.kWarning\n",
    "        \n",
    "        rebinned_list_mean = []\n",
    "        incorrect  = 0\n",
    "        incorrect2 = 0\n",
    "\n",
    "        tf = sw.swift_read_root_file(self.tmpname)\n",
    "        #tf = ROOT.TFile.Open(self.rfile)\n",
    "        #c1 = ROOT.TCanvas('c1','',600,600)\n",
    "        ctools = cameraTools(self.cg)\n",
    "        #print(\"Reconstructing event range: \",evrange[1],\"-\",evrange[2])\n",
    "        # loop over events (pictures)\n",
    "        for iobj,key in enumerate(tf.GetListOfKeys()) :\n",
    "\n",
    "            t1_start = time.perf_counter()\n",
    "            iev = int(iobj/2) if self.options.daq == 'midas' and self.options.pmt_mode else iobj\n",
    "            #print(\"max entries = \",self.options.maxEntries)\n",
    "            if self.options.maxEntries>0 and iev==max(evrange[0],0)+self.options.maxEntries: break\n",
    "            if sum(evrange[1:])>-2:\n",
    "                if iev<evrange[1] or iev>evrange[2]: continue\n",
    "\n",
    "            name=key.GetName()\n",
    "            obj=key.ReadObj()\n",
    "\n",
    "            # Routine to skip some images if needed\n",
    "            if iev in self.options.excImages: continue\n",
    "\n",
    "            if obj.InheritsFrom('TH2'):\n",
    "                if self.options.daq == 'btf':\n",
    "                    run,event=(int(name.split('_')[0].split('run')[-1].lstrip(\"0\")),int(name.split('_')[-1].lstrip(\"0\")))\n",
    "                elif self.options.daq == 'h5':\n",
    "                    run,event=(int(name.split('_')[0].split('run')[-1]),int(name.split('_')[-1]))\n",
    "                else:\n",
    "                    run,event=(int(name.split('_')[1].split('run')[-1].lstrip(\"0\")),int(name.split('_')[-1].split('ev')[-1]))\n",
    "                #print(\"Processing Run: \",run,\"- Event \",event,\"...\")\n",
    "                \n",
    "                testspark=100*self.cg.npixx*self.cg.npixx+9000000\n",
    "                if obj.Integral()>testspark:\n",
    "                          print(\"Run \",run,\"- Event \",event,\" has spark, will not be analyzed!\")\n",
    "                          continue\n",
    "                            \n",
    "                self.outTree.fillBranch(\"run\",run)\n",
    "                self.outTree.fillBranch(\"event\",event)\n",
    "                self.outTree.fillBranch(\"pedestal_run\", int(self.options.pedrun))\n",
    "\n",
    "            if self.options.camera_mode:\n",
    "                if obj.InheritsFrom('TH2'):\n",
    "\n",
    "                    # Upper Threshold full image\n",
    "                    pic_fullres = obj.Clone(obj.GetName()+'_fr')\n",
    "                    img_fr = hist2array(pic_fullres).T\n",
    "\n",
    "                    # Upper Threshold full image\n",
    "                    img_cimax = np.where(img_fr < self.options.cimax, img_fr, 0)\n",
    "                    \n",
    "                    # zs on full image + saturation correction on full image\n",
    "                    if self.options.saturation_corr:\n",
    "                    \t#print(\"you are in saturation correction mode\")\n",
    "                    \timg_fr_sub = ctools.pedsub(img_cimax,self.pedarr_fr)\n",
    "                    \timg_fr_satcor = ctools.satur_corr(img_fr_sub) \n",
    "                    \timg_fr_zs  = ctools.zsfullres(img_fr_satcor,self.noisearr_fr,nsigma=self.options.nsigma)\n",
    "                    \timg_rb_zs  = ctools.arrrebin(img_fr_zs,self.rebin)\n",
    "                        \n",
    "                    # skip saturation and set satcor =img_fr_sub \n",
    "                    else:\n",
    "                        #print(\"you are in poor mode\")\n",
    "                        img_fr_sub = ctools.pedsub(img_cimax,self.pedarr_fr)\n",
    "                        img_fr_satcor = img_fr_sub  \n",
    "                        img_fr_zs  = ctools.zsfullres(img_fr_satcor,self.noisearr_fr,nsigma=self.options.nsigma)\n",
    "                        img_rb_zs  = ctools.arrrebin(img_fr_zs,self.rebin)\n",
    "                    #print(np.asarray(img_fr_sub).shape)\n",
    "                    #print(np.asarray(img_fr_satcor).shape)\n",
    "                    #print(np.asarray(img_fr_zs).shape)\n",
    "                    #print(np.asarray(img_rb_zs).shape)\n",
    "                                        \n",
    "                    # zs on full image + saturation correction on full image\n",
    "                    #algo = 'DBSCAN'\n",
    "                    #if self.options.type in ['beam','cosmics']: algo = 'HOUGH'\n",
    "                    #snprod_inputs = {'picture': img_rb_zs, 'pictureHD': img_fr_satcor, 'picturezsHD': img_fr_zs, 'pictureOri': img_fr, 'vignette': self.vignmap, 'name': name, 'algo': algo}\n",
    "                    #plotpy = self.options.jobs < 2 # for some reason on macOS this crashes in multicore\n",
    "                    #snprod_params = {'snake_qual': 3, 'plot2D': False, 'plotpy': False, 'plotprofiles': False}\n",
    "                    #snprod = SnakesProducer(snprod_inputs,snprod_params,self.options,self.cg)\n",
    "\n",
    "                    #snakes = snprod.run()\n",
    "\n",
    "\n",
    "                    #rebor = ctools.arrrebin(img_fr_zs,2048//n)\n",
    "                    rebor = ctools.arrrebin(img_fr_zs,2048//n)\n",
    "                    rebinned_list_mean.append(rebor)\n",
    "                    #rebor2 = ctools.arrrebin(img_fr_satcor,512)\n",
    "                 \n",
    "                    #if (np.amax(rebor) < 0.461):\n",
    "                    #    incorrect += 1\n",
    "                    #if (np.amax(rebor2) < -0.006):\n",
    "                    #    incorrect2 += 1\n",
    "                    if (np.amax(rebor) < 0.5):\n",
    "                        #if (iobj in [14, 292, 400, 696, 928]):\n",
    "                        #    print(\"Iobj\",iobj,\"correctly removed by mean lower than 0.461\")\n",
    "                        #else:\n",
    "                        #print(\"Iobj\",iobj,\"incorrectly removed by mean lower than 0.461\")\n",
    "                            #print(\"lost by mistake, max value is\",np.amax(rebor))\n",
    "                    #        print(len(snakes), \"lost by mistake, max value is\",np.amax(rebor))\n",
    "                        incorrect += 1\n",
    "                    else:\n",
    "                        incorrect2 += 1\n",
    "                        #print(incorrect, \"selected incorectly so far\")\n",
    "                    #elif(len(snakes) == 0):\n",
    "                    #    print(\"AAAH sem sinal e passou, mula\" + str(iobj))\n",
    "                    #if (np.amax(rebor2) < -0.006):\n",
    "                    #    if (iobj in [14, 292, 400, 696, 928]):\n",
    "                    #        print(\"Iobj\",iobj,\"correctly removed by mean lower than 0.005\")\n",
    "                    #    else:\n",
    "                    #        print(\"Iobj\",iobj,\"incorrectly removed by mean lower than 0.005\")\n",
    "                            #print(\"lost by mistake, max value is\",np.amax(rebor))\n",
    "                    #        print(len(snakes), \"lost by mistake, max value is\",np.amax(rebor))\n",
    "                    #        incorrect2 += 1\n",
    "                    #        print(incorrect2, \"selected incorectly so far\")\n",
    "                    #elif(len(snakes) == 0):\n",
    "                    #    print(\"AAAH sem sinal e passou, mula iobj:\" + str(iobj))\n",
    "\n",
    "\n",
    "\n",
    "        ROOT.gErrorIgnoreLevel = savErrorLevel\n",
    "\n",
    "        print(\"Total Incorrect=\"+str(incorrect)+\" Correct=\"+str(incorrect2))\n",
    "        return rebinned_list_mean\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    for entry in path.iterdir():\n",
    "        print(entry.name)\n",
    "\n",
    "        from optparse import OptionParser\n",
    "\n",
    "        parser = OptionParser(usage='%prog h5file1,...,h5fileN [opts] ')\n",
    "        parser.add_option('-r', '--run', dest='run', default='02163', type='string', help='run number with 5 characteres')\n",
    "        parser.add_option('-j', '--jobs', dest='jobs', default=1, type='int', help='Jobs to be run in parallel (-1 uses all the cores available)')\n",
    "        parser.add_option(      '--max-entries', dest='maxEntries', default=numberofevents[0], type='float', help='Process only the first n entries')\n",
    "        parser.add_option(      '--pdir', dest='plotDir', default='./', type='string', help='Directory where to put the plots')\n",
    "        parser.add_option(      '--tmp',  dest='tmpdir', default=None, type='string', help='Directory where to put the input file. If none is given, /tmp/<user> is used')\n",
    "        parser.add_option(      '--max-hours', dest='maxHours', default=400, type='float', help='Kill a subprocess if hanging for more than given number of hours.')\n",
    "        parser.add_option('-f', '--frun', dest='yadda', default='02163', type='string', help='run number with 5 characteres')\n",
    "\n",
    "        (options, args) = parser.parse_args()\n",
    "\n",
    "        f = open(\"./configFilef55.txt\", \"r\")\n",
    "        params = eval(f.read())\n",
    "\n",
    "        for k,v in params.items():\n",
    "            setattr(options,k,v)\n",
    "\n",
    "        run = int(options.run)\n",
    "        options.debug_mode = 0\n",
    "        if options.debug_mode == 1:\n",
    "            setattr(options,'outFile','reco_run%d_%s_debug.root' % (run, options.tip))\n",
    "            if options.ev: options.maxEntries = options.ev + 1\n",
    "            #if options.daq == 'midas': options.ev +=0.5 \n",
    "        else:\n",
    "            setattr(options,'outFile','reco_run%05d_%s.root' % (run, options.tip))\n",
    "\n",
    "        if not hasattr(options,\"pedrun\"):\n",
    "            pf = open(\"pedestals/pedruns.txt\",\"r\")\n",
    "            peddic = eval(pf.read())\n",
    "            options.pedrun = -1\n",
    "            for runrange,ped in peddic.items():\n",
    "                if int(runrange[0])<=run<=int(runrange[1]):\n",
    "                    options.pedrun = int(ped)\n",
    "                    #print(\"Will use pedestal run %05d, valid for run range [%05d - %05d]\" % (int(ped), int(runrange[0]), (runrange[1])))\n",
    "                    break\n",
    "            assert options.pedrun>0, (\"Didn't find the pedestal corresponding to run \",run,\" in the pedestals/pedruns.txt. Check the dictionary inside it!\")\n",
    "\n",
    "        setattr(options,'pedfile_fullres_name', 'pedestals/pedmap_run%s_rebin1.root' % (options.pedrun))\n",
    "\n",
    "        #inputf = inputFile(options.run, options.dir, options.daq)\n",
    "\n",
    "        os.environ['USER'] = 'amaro'\n",
    "        os.environ['ROOTSYS'] = '/content/root_build'\n",
    "        USER = os.environ['USER']\n",
    "        tmpdir = '/mnt/ssdcache/' if os.path.exists('/mnt/ssdcache/') else '/content/'\n",
    "        # override the default, if given by option\n",
    "        options.tmpname = str(entry)\n",
    "\n",
    "        if options.justPedestal:\n",
    "            ana = analysis(options)\n",
    "            print(\"Pedestals done. Exiting.\")\n",
    "            if options.donotremove == False:\n",
    "                sw.swift_rm_root_file(options.tmpname)\n",
    "            sys.exit(0)     \n",
    "\n",
    "        ana = analysis(options)\n",
    "        nev = ana.getNEvents() if options.maxEntries == -1 else int(options.maxEntries)\n",
    "        print(\"This run has \",nev,\" events.\")\n",
    "        #print(\"Will save plots to \",options.plotDir)\n",
    "        os.system('cp utils/index.php {od}'.format(od=options.plotDir))\n",
    "\n",
    "        nThreads = 1\n",
    "        if options.jobs==-1:\n",
    "            import multiprocessing\n",
    "            nThreads = multiprocessing.cpu_count()\n",
    "        else:\n",
    "            nThreads = 1\n",
    "\n",
    "        if nThreads>1:\n",
    "            print (\"RUNNING USING \",nThreads,\" THREADS.\")\n",
    "            nj = int(nev/nThreads)\n",
    "            chunks = [(ichunk,i,min(i+nj-1,nev)) for ichunk,i in enumerate(range(0,nev,nj))]\n",
    "            print(chunks)\n",
    "            pool = Pool(nThreads)\n",
    "            ret = list(pool.apply_async(ana,args=(c, )) for c in chunks)\n",
    "            try:\n",
    "                if options.maxHours>0:\n",
    "                    maxTime = options.maxHours * 3600\n",
    "                else:\n",
    "                    # 64-bit integer, converted from nanoseconds to seconds, and subtracting 0.1 just to be in bounds.\n",
    "                    maxTime = 2 ** 63 / 1e9 - 0.1\n",
    "                print([r.get(timeout=maxTime) for r in ret])\n",
    "                pool.close()\n",
    "                pool.terminate()\n",
    "                pool.join()\n",
    "            except TimeoutError:\n",
    "                print(\"except\")\n",
    "                terminate_pool_2(pool)\n",
    "            print(\"Now hadding the chunks...\")\n",
    "            base = options.outFile.split('.')[0]\n",
    "            os.system('{rootsys}/bin/hadd -k -f {base}.root {base}_chunk*.root'.format(rootsys=os.environ['ROOTSYS'],base=base))\n",
    "            os.system('rm {base}_chunk*.root'.format(base=base))\n",
    "        else:\n",
    "            for n in sizes:\n",
    "                ana.beginJob(options.outFile)\n",
    "                rebinned_list_mean = ana.reconstruct(n)\n",
    "                ana.endJob()\n",
    "                np.savetxt(\"../moved_means/%s_%d.txt\"%(entry.name,n),np.array(rebinned_list_mean).reshape(-1,n**2))\n",
    "\n",
    "        #### FOR SOME REASON THIS DOESN'T WORK IN BATCH.\n",
    "        # now add the git commit hash to track the version in the ROOT file\n",
    "        # tf = ROOT.TFile.Open(options.outFile,'update')\n",
    "        # githash = ROOT.TNamed(\"gitHash\",str(utilities.get_git_revision_hash()).replace('\\n',''))\n",
    "        # githash.Write()\n",
    "        # tf.Close()\n",
    "\n",
    "        if options.donotremove == False:\n",
    "            sw.swift_rm_root_file(options.tmpname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T1fk3_teB0PG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt(\"median.txt\",np.array(rebinned_list_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ha0REbKnB1mB"
   },
   "outputs": [],
   "source": [
    "#np.savetxt(\"mean.txt\",np.array(rebinned_list_mean).reshape(-1,(n//2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCGL-eASxk1z"
   },
   "source": [
    "# TODO\n",
    "\n",
    "+ OK Fazer os trem em boxplot\n",
    "+ ver o tempo acima de 8seg\n",
    "+ ver parametro pra fazer seleção de imagem\n",
    "+ check tail by images with many points\n",
    "\n",
    "# TOTALK\n",
    "\n",
    "Cortar evento com energia demais?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cópia de reconstruct.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
